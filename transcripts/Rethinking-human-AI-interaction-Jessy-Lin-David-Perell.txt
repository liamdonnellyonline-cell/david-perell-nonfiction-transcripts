Title: Rethinking human-AI interaction: Jessy Lin & David Perell
URL: https://www.youtube.com/watch?v=tKQNrxSJlwc
Date: 2020-06-09T03:42:53.000Z
Duration: 00:34:29

---

Jesse you're let's start off talking a little bit about cubed in the loop and how you came up with this idea and what you began to see in terms of the issues with the way that people were talking about machine translation yeah definitely so first of all like thank you David because the scholarship has been really great I'm sure like everybody's kind of echoed that thought but I kind of like came into this fellowship with a bunch of ideas related to stuff I'd done research on before as well as like interests I have kind of like going into the future so the idea of the essay really centers around kind of the beginnings of human-computer interaction so I kind of started off talking about some of the history even like you know way before the age of AI when people are thinking about how do humans interact with computers and how that ideas kind of evolved through history as we went from you know these like giant mainframes that sat in like a whole room and had like many people operating it too like personal computers and mobile devices and all these other things that we have today and I started thinking about like you know as we have all of these more interactive or intelligent applications how we can make those more interactive as well using a lot of these same ideas so I think like right now in artificial intelligence and machine learning a lot of people are thinking about how do we make this more intelligent and more like powerful and more able to do like image recognition and speech recognition and like things like that but not thinking as much about how to make it like interactive I'm thinking about like a human user at the end of it so that was kind of the inspiration for the essay yeah one of the things that you're talking about in the essay is this idea of human in the loop and I'll let you explain it at all it's something wrong but I'll do my best to summarize it here the example that I think a lot about is Tesla so Tesla comes out with their self-driving cars and when that happens the computer is operating and that computer is driving the car and so you're on the highway you're on a road and very famously it is fairly easy for computers to do even 99.99% of what is required to drive a car but this problem of self-driving cars it's been a lot more difficult because often computers will miss characterize something that they're seeing and they'll see it actually a person and you cannot and so we've depended on computers to do the driving but then to humans for humans to be his backup layer that when something goes wrong a human stopped texting all the starts putting their attention on the road in front of them but we found that this might not actually be the best way to do machine learning and self-driving cars why what is wrong with this human-in-the-loop model trying to solve these complicated problems yeah definitely so I would say like you know a lot of people naturally think of a self-driving car example because like you know the car drives and then like you kind of have this idea of like okay I can like take it over if something goes wrong but like the fine details of how that handoff or that interaction happens make a big difference right so I have this example in the essay where I think it was the American Bar Association that did some studies on how this like what they call like semi autonomous system works when the machine hands off control to the human and there are details like how does the handoff happen like what kind of information is a human provided with like what context are they aware of is that is there an expectation that they're like attentive to the road even though the car is like kind of operating autonomously and all of these details make a difference as to like how successful the human is at like handling this like you know like upcoming accident or like emergency situation so there's been a lot of I'm thinking recently especially because you know self-driving cars have been on the horizon for a while but for some reason we just like can't get to full autonomy so it's becoming like more and more of a like pressing issue that we need to think about like how can we have this like you know 90% accurate like machine learning autonomous driving system interact with a human in an effective way so I think there's some interesting research that's been going on is in this area of you know like if we think about how the human like interprets the like actions of the system or like maintain some sort of understanding of what's going on how the human plus machine driving system can be more safe and function more properly as a whole you distinguish between human-in-the-loop and humans backup because I think that I was explaining that as I was doing it I was conflating the two and so I want to make sure that we get that really clear before we move on to the reference yeah say and your proposal yeah so even in the loop as you might imagine means like okay there's like some kind of autonomous system and there's a human operating somewhere in the loop but the problem today is that like a lot of people have this very narrow vision of what that might look like where the human and the loop operates as a backup for the machine so the machine you know it's driving and then like if something goes wrong pass it off to the human and you see this in a lot of big other examples as well so if you have like some kind of virtual assistant like maybe like the the like chat BOTS or like whatever machine learning like language processing algorithm you might have handles the requests that it knows how to handle and then hands off to some kind of human assistant when it doesn't know how to handle these examples but kind of the idea that I kind of go on to talk about and the essay is there's a lot a lot more like different ways for humans to interact with machines like in a you know tight more tightly integrated loop or in situations where like the human might initiate and call out to the Machine when needed and things like that so yeah lots of ideas to talk about the two examples that you give one is machine translation so that is actually you give the example of dog Douglas Hofstadter's a famous researcher who wrote g√∂del Escher Bach and he shows what an original German paragraph looks like then he translated translates it himself and then he shows the difference between his own translation and a computer translation to show some of the differences between them so why don't we start there and then we'll get into some of the computer human interaction that's happening at the cutting edge of checks yeah so and Douglas Hofstadter's example he kind of goes through this Germans article and looks at like what are the weaknesses of bullet translate compared to human translators so there is some like quotes from the article there but basically he looks at like specific phrases and how Google Translate translate that translates them compared to a native German speaker and you know from everyday experiences with Google Translate you can imagine like there are a lot of like fine nuanced phrases or semantics that Google Translate doesn't quite capture even though it does give you like the gist of what an article might be saying and he breaks this down and very fine detail looking at like okay when Google Translate translates this article you know like what are the specific phrases that it misses and how does this affect the overall translation at a whole as a whole even after a human goes back and like corrects the translation that comes out of like Google Translate and the difference that you see is like you know because you're starting off with this very unnatural translation even if you have a human like what we call post-edit that translation it looks like like markedly different from what a human translator would produce so the idea here is like you know in a human's is back up human and loop situation we might imagine like Oh you know have a Google Translate translate the sentence and then have a human go back and fix it that's like the same as like a human you know translating it from the beginning because like you know you you passed through human but in reality when you look at the example you'll see like this actually produces like much lower qualities than having a human initiate this loop right yet there's this great quote that you use in the end that from a translator who says something to be effective if I try to translate something back up where the machine went first and I tried to just come in afterwards that would just take me as long as just trying to translate it myself and so what you're saying is because there are so many small little errors but also you could think of the direction that the computer hates the translation on is is fundamentally wrong actually trying to correct the entropy of the translation ends up awesome taking more time or at least as long time it's just doing the translation yourself so from there why don't we get into chess and talk okay that kind of backup post-edit translation when a computer does the work and then we come in after that doesn't work and that's sort of like I'm almost thinking like a lawnmower like you come in and and the lawnmower goes and then you sort of sweep the grass to make sure that there was nothing missed that's why we think of that but you're trying to say something very different which is actually the symbiosis in terms of thinking about how do humans begin to initiate the process of creation and then how do computers come in afterwards so let's talk about Jeff they get really concrete with what exactly you're talking about there yeah so there's this example from the history of chess so this goes back to you you know I think it was like the 1970s or 1980s when we were just beginning to come out with chess a eyes and actually Garry Kasparov was like this great Grandmaster was recently defeated by IBM's trust I hate to say I and he started thinking about like okay like what are some ways to reinvent the game of chess in the age of computers and he came out this idea of freestyle chess which is what if we had humans playing chess using whatever kind of machine assistance or external resources they want so he would have these games where like there are human players just like playing on their own there would be like pure AI players and then there would be like sent our players which are humans using computers and first of all like the first thing that people saw these matches was these hybrid human machine players consistently beat humans human players on their own and machine players on their own so somehow like even though you know like you know the the AI is like competing with with a human like the human contributes something that does better than just the machine on its own and furthermore like when he found was like at one of these tournaments there was like a group of amateur players that we're using like pretty basic computers like you know normal hardware that they got from like their dad and they're using like pretty normal challenges as well while like there were these grandmasters with like super computers and like the most advanced AI and these amateurs were beating these grandmasters and the reason was because they understood at some like deep level what each of their chess a is and chess engines and computers what their strengths and weaknesses were so they're able to you know take the output of one machine and say this engine might be good at opening moves so we're gonna look at it for opening moves and they were gonna use this entrance for like the rest of the game and things like that so using human judgment to kind of take bits and pieces of each of these you know machine generated outputs and use it in a more integrated way so I think like when I heard about this example I think it was like one of the like best examples I've seen of you know the strengths of using human judgment in the loop with a machine and you know since then chess a eyes come a long way but you can imagine that like in applications where what we need is even more open-ended that human judgment can play even bigger and even more significant of the role you know so what parameters does the person need in order to be better with AI like if I completed against a deep-blue IBM chess it would probably be better for the AI to just go on their own because I'm not an expert in chess and I my decisions would probably hurt the algorithms chance of success but then if you bring in a chess master like like Garry Kasparov's there is something that fundamentally different happens and so is my intuition correct in saying that the human needs to be of a sufficient level in order for things to work yeah I would say so and I think that's like one of the interesting questions that I kind of explore in these essays and it's still kind of an open question as well which is like you know like how like what are we designing for here like like who is the human end user what do they know and how do we design the machine to complement the humans abilities so it does depend on like what the what the end user knows right like if you're designing a tool for a domain expert versus like you know David who like has played a bit of trust but like maybe you know isn't like a grandmaster or something and I think like that requires some understanding of the particular application and also like what the strengths and weaknesses of humans are in that particular case so yeah it's definitely like that so do you see a parallel there between that your return to the test for example that we spoke about at the beginning do you see an example there where what then knowing what you know about chess knowing what we've discussed about machine translation and some of the errors with the post edit which is sort of like a humanist backup system how then if you were a product manager or Tesla how would you be thinking about car design differently yeah yeah so I think like there's this really good great quote by Alan Kay so one of the pioneers of human-computer interaction where he says understanding not just that end users have function functioning minds but that about better understanding of those Minds would completely shift how we think about interaction so this goes back to like you know in this case of designing Tesla autopilot thinking about how humans respond in these kind of very like these situations that require a very quick response that require like split-second judgments that require like taking stock of like your perceptual surroundings like understanding that can really shift how we think about designing autopilot and even on the other side like when we're designing autopilot thinking about how other drivers on the road understand their surroundings as well so like a lot of these emerging self-driving car approaches involve these this field of research called like theory of mind which is understanding how somebody else is like thinking about the situation so you know when you know let me like contrast you approaches for example so if I'm like driving on the road and I see this other car kind of like shifting into my lane a bit as a driver like as a human driver I understand what that means because I can imagine like oh if I were in that car situation how would I kind of signal that I wanted to move into this Lane well I would like you know like put on the signal and like maybe like start driving a little bit in that direction the signal that I'm like starting to move towards you and like I would have an understanding of that because like I understand other people's goals and intentions like I have to use mine whereas like in AI what they see is like there's a car and it like has moved five pickle five pixels to the left so a lot of these emerging self-driving car approaches are starting to think about like how can we use our understanding of human psychology to build more capable machines that interact in a human world so London's even beyond that like stay that car moves five pixels to the left it could be a couple different things it could also mean that there is on the right side of the road and that that car is trying to avoid something so you could say if the car is just trying to get into your lane very casually because they're trying to pass the car in front of them that might be 80 yards ahead of them it's very casual thing then you just want to slow down and maybe not even hit hit the brake so that your red lights in the back come on because that will have downstream effects maybe you just want to ease off the gas but there could be another scenario where that driver is coming into your lane because there might be a tire that is rolling across the street and then you actually have to swerve left provided that there's no car behind you then it gets really complicated but the thing is these are these edge cases but that is when accidents happen it's quite good enough for people to just take their hands off the wheel the car yeah yeah definitely so a lot of these little like ways that people signal to each other like that counts as a sort of interaction as well absolutely Tucker Google's part reply I really like this example that you gave in terms of what good interaction between humans and computers could be yeah yeah so a little smart reply for people who haven't seen it as this feature in Gmail where you're like composing an email and then it kind of like autocompletes your sentence based on similar sentences that you and other people have typed in the past right so this this kind of style of interaction can be applied in a lot different different places so the place that I talk about in this essay is translation so if I'm a translator you know again like one way to interact with the machine is to edit the output that the machine is already generated but another way is to take the translators workflow which is typing a translation and just like like level it up a little bit or like supercharging a little bit with these google smart replies autocomplete translations yeah so the animation I think the essay kind of illustrates it better but like you can imagine as a translator I'll I'll be translating and if it's a routine translation the machine can just fill it in for me I can like tab to autocomplete if it's a different sort of more creative phrase than what I can do is just continue typing I don't need to you know I don't need to deal with the machines output I can just like do what I normally do so I think this kind of interaction is a bit more natural in that I is the translator or I is the human initiate the workflow and call out to the Machine when I need to and just do my thing when I don't exactly exactly and the other thing is often I wonder if you'll be able to signal to the machine like I want you to complete this so I'm thinking about for example one thing that drives me crazy is like when I do my drawing looks like fur for my SAS or about my web site I have to go specify how I want the line yeah and that is so manual that I wanted to be like a hundred percent straight eighty nine percent straight and then I always have to make little mistakes I want it to be a little bit different but what I would much rather have is four start drawing the line and for the Machine that app to then give me a bunch of different options and then I just click that straight line option and then an autocomplete from the straight line option and then I have the straight line option but say that I actually just want some edges and I want to make them nice sort of like s-curve then I want to be able to without even telling the computer to have the computer realized that that's what I'm trying to do then once they make like four of them to then have the entire s-curves autocomplete and I can see that showing up everywhere where what a computer what a human does is they get the path started and then the computer actually figures out what the rest of the pattern is it's sort of like when you're in school like even on SAT problems so give you a pattern that's like city you're going three six nine 12 the next one's gonna be 15 but then very often like if they're clever what they'll do is they'll say it's 3 6 9 but then to the 12 and then the next one will be like 34 and they'll end up being some pattern that the retrospect is really obvious but when you're doing it it didn't seem like the most logical one and then you can avoid the computer suggestion and go on to 34 and that's the kind of relationship that we want with computers that we don't have yet yeah yeah definitely and I think like a lot of these ideas merge really well with this emerging like tools for Thought movement where it's like how can we build machines or tools that can help us think better and I think the intersection here is like well you know with all these powerful new machine learning algorithms and like more intelligent tools like we have a better sense of how to like help people do things like draw or write or manage information and things like that so I think the possibilities there are pretty cool how much you as a researcher worry about the idea that there is also knowledge in these artificial intelligence algorithms that we don't actually know about so you gave the example of in one hospital the diagnoses were different from the other ones but then there were certain reasons from not talk about that example because that's what concerns me there's like this intellectual dark matter embedded within the knowledge and we actually can create the systems but we can't actually piece out all the knowledge that is coming together in order for those systems to work yeah definitely so this is like a super kind of right area of research so I would refer people to like interpretability explain ability and research on like fairness and machine learning which looks at basically like how can we open up the black box and machine learning how can we like make the outputs or like the reasons that a machine outputted a particular thing comprehensible to humans so this is applicable and like like you mentioned like medical diagnosis where if we make a diagnosis we want to understand like what the factors are that contributed to that diagnosis one to make sure like okay like as a doctor I want to make sure just a sanity check the machine is actually using predictive variables that are relevant for this particular patient so you know like in the example that I talked about in the essay there are some machine learning algorithms like that might be trained on biased datasets where like all the patients from one Hospital have the disease and all the patients for another hospital don't maybe like one Hospital is far more severe cases and therefore like there's this inherent bias in the data and because like we're not imposing any source of sort of like domain knowledge like you know the choice of hospital doesn't matter or a particular diagnosis this happens just to be like a spurious correlation the machine is picking up on these correlations and using them to predict like incorrect outcomes so I would say like yeah like people are thinking about this a lot about how to make machines like more fair more like unbiased but it's definitely something that is still an open problem and I think a lot of the reason why interaction might be like a really good approach to kind of manage these risks because if I'm interacting with the machine like or if I'm initiating the workflow I can kind of like manage how the machine fits in to the larger context so I can like use it in very specific situations where I know like okay I just want to understand like you know this like what the machine thinks about this particular thing and like I'm still kind of like as a doctor managing like all the other information about the patient I'm not just like relying entirely on the machine to diagnose like without like doctor oversight or something so yeah so I'm gonna throw it in their name you tell me where it's right where it's wrong so there's a big narrative that has swept across the AI landscape from what I've observed which is if you have more data you will automatically win because more data creates this compounding exponential effect and you end up with these small advantages but then because of the nature of compounding those small advantages get bigger and bigger and bigger over time and you end up having such a data advantage that nobody can compete with you true or false yeah I think this is a really hot question as well like I think we've been surprised by how effective data is like a lot of things we didn't think we could do we could do just because we collected bigger data sets and built bigger models like a lot of let's say like speech recognition or language understanding seems to come about when we have just like you know 100-plus GPUs thrown at the problem but I I would say like a lot of the things that people are seeing industry is like one this is very expensive and not sustainable as a strategy and two we're not even sure like whether we can get to human level understanding just by throwing more data at the problem so like self-driving cars it's the most obvious example where we just like you know we've thrown so many resources not only like computer resources but like human resources at the problem and we still haven't gotten to the point of full autonomy so like the question is like are we willing to take the risk or you know do we want to kind of like think about the possibility that it's not an exponential curve but like a curve that flattens out over time and what we need maybe at some point is like another research breakthrough before we can really get to full autonomy or language understanding or like human level reasoning do you have a sense of why we say Google Translate why that has gotten so good like the big one for me it's like when I go okay Google and I type into it and I say just had a really good Congress with Jessie it's a beautiful Sunday in San Francisco and now I'm gonna go on a walk with my mom if I type that into Google it's so much better than doing that into Siri so we've got a data thing is that like a way of actually the way that the Google algorithms work that are better maybe apples really bad like what's actually going on there yeah I would say in that case it's like a combination of like the data and the particular like model that Siri might using versus Google I think in other cases like you know a big problem that startups have is like a barely data problem so like even though they might have like PhD students on like the founding team as a start-up you just can't compete with like the same sources of data that Google has for a lot of these applications so yeah definitely like a combination of both which is really interesting so then what are the solutions they're like could you start a company that's just like hey we have a ton of data and that's all that we do we just open source data we clean it up so yeah solution for that as for the data problem and like how it applies to startups yes that is a big problem that startup space and I think a lot of the reason why people turn to humans in the loop which is like you know as a start-up that wants to incorporate some machine learning technology I need some data to like bootstrap this process how do I get that data either I use open source datasets which is thankfully like in the machine learning community pretty common like for a lot of these papers that are published they also like release a data set to help the community kind of work on the same problem but if I'm working on a sort of proprietary problem like I want to label product images and like I need to train on specific products I might incorporate a human in the loop to label data while I'm building up my model so like this is like the whole kind of I guess like playbook strategy for machine learning startups nowadays which is to start the flywheel of having machine learning algorithm and then having this like human is back up to label the examples that are hard but the argument that I'm kind of presenting in this in this essay is thinking more about like you know as a start-up you can do that you can't have a humanist back up to label these hard examples but you can also start with a human for a strategy and still collect the data you need to you know gain the advantage and like build a better model and so on by thinking about how you can integrate better with humans from the beginning how much my guy friend who runs had a big investment firm in the firm and one of the most surprising things that I've learned from him is inordinate about the company resources just goes into cleaning up the data that the data they actually get even though they're buying the data even though it's really high quality even though it's from great sources and it's advertised that it's good clean data even then they have to continue to clean it up how would you weigh the difference in priority and I'm sure there's a context-dependent element here but how priority between cleaning up data and then just trying to get more data that's a good question I would say like both are pretty important so you know having clean data is important because like you know if you have there's a fridge pull like garbage in garbage out right right yeah that on you train out your model and you're gonna have bad results but then at a certain point like you also need a like critical mass of or you need like a lot of data to train these algorithms in the first place but like the problem is like you know you need both you need high quality and lots of it so that's kind of the problem that people face and last question I mean constraint is on acquiring data so is it that we don't have enough sensors is it a privacy issue that doesn't allow us to collect data is it a sharing issue that a lot of the data is locked into the wall gardens of Facebook and Google and Apple what is actually preventing more data from being captured like you should even take something like a Stephen Wolfram Alpha we're in Wolfram Alpha the the language it allows us to look at real world data that we wouldn't have in other systems and so it's like making new parts of the world legible so what is the binding constraint on us not having ten times more data which would allow us to have more food to give our training sense yeah I mean I would say just like getting high-quality labeled datasets in general requires a lot of labor so like if I want to let's say train a machine to answer questions I need to have like a high quality data set of questions and answers and who is going to produce the answers like human labor and a lot of that times that labor can be very expensive like if you're you know like a medical application for example you need doctors to like label these examples you can't just have some you know like low cost worker in another country doing that so really I think like for every application you need like a very high quality to help tailor data set for that application and that's a lot of what the bottleneck is for a lot of these startups and companies Jesse Lee congratulations on your essay thank you David thank you so much for the fellowship